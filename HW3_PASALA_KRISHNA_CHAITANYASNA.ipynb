{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyzjyN5191MH"
   },
   "source": [
    "**Quora duplicates detection**\n",
    "\n",
    "`Deadline: 2.12.2021 23:59 msk`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF_2-ZwQ6REd"
   },
   "source": [
    "In this homework you will learn 1) how to build an LSTM-based siamese homework and search for the duplicates in quora question pairs dataset; 2) how to use Sentence BERT and fine-tune it for the same task. Then we will compare the final quality.\n",
    "\n",
    "The homework is based on DeepLearning.AI materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-y4-Efg0em1"
   },
   "source": [
    "**Part 1: Loading the dataset & Looking at it** (3 points)\n",
    "\n",
    "For this task a well-known quora duplicate detection dataset will be used. We put the data to the \"sample_data\" folder in the current runtime (not the best option) but you are free to mount a google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jmrTQzgF0eUi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3bScUvhN2C6o"
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0n6d8EN00WLg"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH_TO_DATA, 'train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFfnhCFW26vr"
   },
   "source": [
    "As you can see the data consists of questions, and the indicator whether they are duplicate or not. Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b-JcY6iH24d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OO9VZcJ0j607"
   },
   "outputs": [],
   "source": [
    "data = data[~data['question1'].isna()]\n",
    "data = data[~data['question2'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eXadVeLM3db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What is the step by step guide to invest in share market in india?\n",
      "Q2: What is the step by step guide to invest in share market?\n"
     ]
    }
   ],
   "source": [
    "# non-duplicate example\n",
    "questions = data[data['is_duplicate'] == 0].loc[0]\n",
    "print(f'Q1: {questions.question1}\\nQ2: {questions.question2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OvrxBczp4izO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: How can I be a good geologist?\n",
      "Q2: What should I do to be a great geologist?\n"
     ]
    }
   ],
   "source": [
    "# duplicate example\n",
    "questions = data[data['is_duplicate'] == 1].loc[7]\n",
    "print(f'Q1: {questions.question1}\\nQ2: {questions.question2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT2EaDep2W9z"
   },
   "source": [
    "Now the dataset is going to be divided into train and test parts for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FFj2KfIZ2Vsv"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, stratify=data['is_duplicate'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fcUue2o3qKY"
   },
   "source": [
    "**Task:** Do a little exploratory analysis. Find how many duplicates and non-duplicates are there in the train part and any other actions of your interest to better understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DJtqh5Fh3lSV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              111947\n",
       "qid1            111947\n",
       "qid2            111947\n",
       "question1       111947\n",
       "question2       111947\n",
       "is_duplicate    111947\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "train[train['is_duplicate'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='is_duplicate'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby(\"is_duplicate\")['id'].count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of  Unique Questions are: 427623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique=len(set(list(train['qid1'])+list(train['qid2'])))\n",
    "print ('Total number of  Unique Questions are: {}\\n'.format(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606430"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train['qid1'])+list(train['qid2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxR1jr-H7BS-"
   },
   "source": [
    "Now let's leave only positive examples to train the network. As we remember the negative examples for each of the anchors are taken from the same batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MY7IhUTC6-Xo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 111947\n"
     ]
    }
   ],
   "source": [
    "train_idx = train[train['is_duplicate'] == 1].id.tolist()\n",
    "print(f'Number of training examples: {len(train_idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WKeH69m29eaR"
   },
   "outputs": [],
   "source": [
    "q1_train_data = np.array(train.loc[train_idx, 'question1'])\n",
    "q2_train_data = np.array(train.loc[train_idx, 'question2'])\n",
    "q1_test_data = np.array(test['question1'])\n",
    "q2_test_data = np.array(test['question2'])\n",
    "\n",
    "q1_train = np.empty_like(q1_train_data)\n",
    "q2_train = np.empty_like(q2_train_data)\n",
    "q1_test = np.empty_like(q1_test_data)\n",
    "q2_test = np.empty_like(q2_test_data)\n",
    "\n",
    "y_test  = np.array(test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KYNtvi-LAJkb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Can a Gemini man and a Gemini woman have a successful relationship? Or are they incompatible?',\n",
       "       'How can I delete my own question from Quora?',\n",
       "       'Why are there still people who think that the Earth is flat?',\n",
       "       'What should I do to concentrate more on my studies?',\n",
       "       'How can one stop caring too much?'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hE_eRrAl-FxD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is:  36377\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "vocab = defaultdict(lambda: 0)\n",
    "vocab['<PAD>'] = 1\n",
    "\n",
    "for idx in range(len(q1_train_data)):\n",
    "    q1_train[idx] = nltk.word_tokenize(q1_train_data[idx])\n",
    "    q2_train[idx] = nltk.word_tokenize(q2_train_data[idx])\n",
    "    q = q1_train[idx] + q2_train[idx]\n",
    "    for word in q:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab) + 1\n",
    "print('Vocabulary size is: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "d2f0RIfqAlfp"
   },
   "outputs": [],
   "source": [
    "# processing test\n",
    "\n",
    "for idx in range(len(q1_test_data)): \n",
    "    q1_test[idx] = nltk.word_tokenize(q1_test_data[idx])\n",
    "    q2_test[idx] = nltk.word_tokenize(q2_test_data[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU5GpZ8FcCqD"
   },
   "source": [
    "Converting the examples to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "D-p0gyNAbx8c"
   },
   "outputs": [],
   "source": [
    "for i in range(len(q1_train)):\n",
    "    q1_train[i] = [vocab[word] for word in q1_train[i]]\n",
    "    q2_train[i] = [vocab[word] for word in q2_train[i]]\n",
    "\n",
    "        \n",
    "for i in range(len(q1_test)):\n",
    "    q1_test[i] = [vocab[word] for word in q1_test[i]]\n",
    "    q2_test[i] = [vocab[word] for word in q2_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([2, 3, 4, 5, 6, 3, 4, 7, 8, 3, 9, 10, 11, 12, 13, 14, 15, 11]),\n",
       "       list([23, 24, 25, 26, 27, 28, 29, 30, 31, 11]),\n",
       "       list([36, 13, 37, 38, 39, 40, 41, 42, 18, 43, 17, 44, 11]), ...,\n",
       "       list([200, 782, 344, 50, 25, 827, 472, 10832, 11]),\n",
       "       list([692, 25, 4191, 55, 3922, 1163, 11, 36, 11]),\n",
       "       list([524, 266, 162, 1274, 51, 58, 614, 11, 258, 853, 21, 468, 11])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmSb_dZglAoj"
   },
   "source": [
    "To check the model quality we are going to divide the train part into train and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sdTr2iqck_M3"
   },
   "outputs": [],
   "source": [
    "q1_train, q1_val, q2_train, q2_val = train_test_split(q1_train, q2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27987,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6MLdSiPDcZ4a"
   },
   "outputs": [],
   "source": [
    "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
    "    \"\"\"Generator function that yields batches of data\n",
    "\n",
    "    Args:\n",
    "        Q1 (list): List of transformed (to tensor) questions.\n",
    "        Q2 (list): List of transformed (to tensor) questions.\n",
    "        batch_size (int): Number of elements per batch.\n",
    "        pad (int, optional): Pad character from the vocab. Defaults to 1.\n",
    "        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
    "    Returns:\n",
    "        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
    "        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
    "              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
    "    \"\"\"\n",
    "\n",
    "    input1 = []\n",
    "    input2 = []\n",
    "    idx = 0\n",
    "    len_q = len(Q1)\n",
    "    question_indexes = [*range(len_q)]\n",
    "    \n",
    "    if shuffle:\n",
    "        rnd.shuffle(question_indexes)\n",
    "    \n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    while True:\n",
    "        if idx >= len_q:\n",
    "            # if idx is greater than or equal to len_q, set idx accordingly \n",
    "            # (Hint: look at the instructions above)\n",
    "            idx = 0\n",
    "            # shuffle to get random batches if shuffle is set to True\n",
    "            if shuffle:\n",
    "                rnd.shuffle(question_indexes) \n",
    "        \n",
    "        # get questions at the `question_indexes[idx]` position in Q1 and Q2\n",
    "        q1 = Q1[question_indexes[idx]]\n",
    "        q2 = Q2[question_indexes[idx]]\n",
    "        \n",
    "        # increment idx by 1\n",
    "        idx += 1\n",
    "        # append q1\n",
    "        input1.append(q1)\n",
    "        # append q2\n",
    "        input2.append(q2)\n",
    "        if len(input1) == batch_size:\n",
    "            # determine max_len as the longest question in input1 & input 2\n",
    "            # Hint: use the `max` function. \n",
    "            # take max of input1 & input2 and then max out of the two of them.\n",
    "            max_len = max(max([len(i) for i in input1]),max([len(j) for j in input2]))\n",
    "            # pad to power-of-2 (Hint: look at the instructions above)\n",
    "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
    "            b1 = [] \n",
    "            b2 = [] \n",
    "            for q1, q2 in zip(input1, input2):\n",
    "                # add [pad] to q1 until it reaches max_len\n",
    "                q1 = q1 + [pad] * (max_len - len(q1))\n",
    "                # add [pad] to q2 until it reaches max_len\n",
    "                q2 = q2 + [pad] * (max_len - len(q2))                \n",
    "                # append q1\n",
    "                b1.append(q1)\n",
    "                # append q2\n",
    "                b2.append(q2)\n",
    "            # use b1 and b2\n",
    "            yield np.array(b1), np.array(b2)\n",
    "    ### END CODE HERE ###\n",
    "            # reset the batches\n",
    "            input1, input2 = [], []  # reset the batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln52P66E9ck1"
   },
   "source": [
    "**Part 2: Buiding the siamese network** (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BrUMMrg31m9f"
   },
   "outputs": [],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.supervised import training\n",
    "\n",
    "def Siamese(vocab_size=33000, d_model=128, mode='train'):\n",
    "    \"\"\"Returns a Siamese model.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).\n",
    "        d_model (int, optional): Depth of the model. Defaults to 128.\n",
    "        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch Siamese model. \n",
    "    \"\"\"\n",
    "\n",
    "    def normalize(x):  # normalizes the vectors to have L2 norm 1\n",
    "        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\n",
    "    \n",
    "    # your code (Replace instances of 'None' with your code) ###\n",
    "    q_processor = tl.Serial( #nn.Sequential(\n",
    "        tl.Embedding(vocab_size, d_model), # Embedding layer\n",
    "        tl.LSTM(d_model), # LSTM layer\n",
    "        tl.Mean(axis=1), # Mean over columns\n",
    "        tl.Fn(\"Normalize\", normalize)  # Apply normalize function\n",
    "    )\n",
    "    \n",
    "    # Try to run on Q1 and Q2 in parallel.\n",
    "    model = tl.Parallel(q_processor, q_processor)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parallel_in2_out2[\n",
       "  Serial[\n",
       "    Embedding_33000_128\n",
       "    LSTM_128\n",
       "    Mean\n",
       "    Normalize\n",
       "  ]\n",
       "  Serial[\n",
       "    Embedding_33000_128\n",
       "    LSTM_128\n",
       "    Mean\n",
       "    Normalize\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Siamese()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EL2mEjee2Tx"
   },
   "source": [
    "**Part 3: Measuring the quality** (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EcHwH7ke5i_"
   },
   "source": [
    "To calculate loss we will use `Triplet Loss`. The result of loss calculation in batch are values of similarity that should be the highest on the main diagonal (`np.diagonal`) and the second \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "h3zXj7i8gx7L"
   },
   "outputs": [],
   "source": [
    "import trax.fastmath.numpy as fastnp\n",
    "\n",
    "def TripletLossFn(v1, v2, margin=0.25):\n",
    "    \"\"\"Custom Loss function.\n",
    "\n",
    "    Args:\n",
    "       v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.\n",
    "       v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.\n",
    "       margin (float, optional): Desired margin. Defaults to 0.25.\n",
    "\n",
    "    Returns:\n",
    "       jax.interpreters.xla.DeviceArray: Triplet Loss.\n",
    "    \"\"\"\n",
    "    # use fastnp to take the dot product of the two batches (don't forget to transpose the second argument)\n",
    "    scores = fastnp.dot(v1, v2.T)\n",
    "    # calculate new batch size\n",
    "    batch_size = len(scores)\n",
    "    # use fastnp to grab all postive =diagonal= entries in =scores=\n",
    "    positive = fastnp.diagonal(scores)  # the positive ones (duplicates)\n",
    "    # multiply =fastjnp.eye(batch_size)= with 2.0 and subtract it out of =scores=\n",
    "    negative_without_positive = scores - (fastnp.eye(batch_size) * 2.0)\n",
    "    # take the row by row =max= of =negative_without_positive=. \n",
    "    # Hint: negative_without_positive.max(axis = [?])  \n",
    "    closest_negative = fastnp.max(negative_without_positive, axis=1)\n",
    "    # subtract =fastjnp.eye(batch_size)= out of 1.0 and do element-wise multiplication with =scores=\n",
    "    negative_zero_on_duplicate = (1.0 - fastnp.eye(batch_size)) * scores\n",
    "    # use =fastjnp.sum= on =negative_zero_on_duplicate= for =axis=1= and divide it by =(batch_size - 1)= \n",
    "    mean_negative = fastnp.sum(negative_zero_on_duplicate, axis=1)/(batch_size - 1)\n",
    "    # compute =fastjnp.maximum= among 0.0 and =A=\n",
    "    # A = subtract =positive= from =margin= and add =closest_negative= \n",
    "    triplet_loss1 = fastnp.maximum(0, margin - positive + closest_negative)\n",
    "    # compute =fastjnp.maximum= among 0.0 and =B=\n",
    "    # B = subtract =positive= from =margin= and add =mean_negative=\n",
    "    triplet_loss2 = fastnp.maximum(0, (margin - positive) + mean_negative)\n",
    "    # add the two losses together and take the =fastjnp.mean= of it\n",
    "    triplet_loss = fastnp.mean(triplet_loss1 + triplet_loss2)\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4sdTieIyhxki"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Loss: 0.5\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
    "v2 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
    "print(\"Triplet Loss:\", TripletLossFn(v1,v2)) # expecting 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uNuJrrfgh4KU"
   },
   "outputs": [],
   "source": [
    "# make your function a layer\n",
    "from functools import partial\n",
    "def TripletLoss(margin=0.25):\n",
    "    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n",
    "    return layers.Fn('TripletLoss', triplet_loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeoP1MHWiFg0"
   },
   "source": [
    "**Part 4: Training the model** (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6jUFX8BiJ7Z"
   },
   "source": [
    "To train the model we should define cost function and optimizer and the model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hIRB8ySRh-mU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Q1.shape  (83960,) (83960,)\n",
      "val_Q1.shape    (27987,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "# q1_train, q2_train, q1_val, q2_val \n",
    "train_generator = data_generator(q1_train, q2_train, batch_size, vocab['<PAD>'])\n",
    "val_generator = data_generator(q1_val, q2_val, batch_size, vocab['<PAD>'])\n",
    "print('train_Q1.shape ', q1_train.shape, q2_train.shape)\n",
    "print('val_Q1.shape   ', q1_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SgDRIojakyJn"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import trax\n",
    "from trax import layers\n",
    "import numpy\n",
    "def train_model(Siamese, TripletLoss, train_generator, val_generator, output_dir=\"./models/\",\n",
    "                steps_per_checkpoint=100):\n",
    "    \"\"\"Training the Siamese Model\n",
    "\n",
    "    Args:\n",
    "       Siamese (function): Function that returns the Siamese model.\n",
    "       TripletLoss (function): Function that defines the TripletLoss loss function.\n",
    "       lr_schedule (function): Trax multifactor schedule function.\n",
    "       train_generator (generator, optional): Training generator. Defaults to train_generator.\n",
    "       val_generator (generator, optional): Validation generator. Defaults to val_generator.\n",
    "       output_dir (str, optional): Path to save model to. Defaults to 'model/'.\n",
    "\n",
    "    Returns:\n",
    "       trax.supervised.training.Loop: Training loop for the model.\n",
    "    \"\"\"\n",
    "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(400, 0.01)\n",
    "    output_dir = Path(output_dir).expanduser()\n",
    "\n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    steps_per_checkpoint=100\n",
    "    train_task = trax.supervised.training.TrainTask(\n",
    "        labeled_data=train_generator,      \n",
    "        loss_layer=TripletLoss(),        \n",
    "        optimizer=trax.optimizers.Adam(0.01),          \n",
    "        lr_schedule=lr_schedule, \n",
    "        n_steps_per_checkpoint=steps_per_checkpoint,\n",
    "    )\n",
    "\n",
    "    eval_task = trax.supervised.training.EvalTask(\n",
    "        labeled_data=val_generator,       \n",
    "        metrics=[TripletLoss()],         \n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    training_loop = trax.supervised.training.Loop(Siamese(),\n",
    "                                                  train_task,\n",
    "                                                  eval_tasks=[eval_task],\n",
    "                                                  output_dir=output_dir)\n",
    "\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "N6Nd4sEgl6f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk/anaconda3/lib/python3.8/site-packages/jax/_src/lib/xla_bridge.py:412: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random as rnd\n",
    "\n",
    "# %%time\n",
    "train_steps = 5\n",
    "training_loop = train_model(Siamese, TripletLoss, train_generator, val_generator)\n",
    "training_loop.run(train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((array([[ 0.11875313,  0.05593207, -0.07987386, ...,  0.01123042,\n",
       "            0.13157398,  0.05508289],\n",
       "          [ 0.08577887, -0.08110738, -0.68326616, ..., -0.49868444,\n",
       "            0.01074426,  0.0485232 ],\n",
       "          [ 0.04366594,  0.11449299, -0.13759665, ...,  0.2349906 ,\n",
       "           -0.06320382,  0.14746805],\n",
       "          ...,\n",
       "          [-0.07580012,  0.1814747 , -0.14015569, ..., -0.0378515 ,\n",
       "           -0.08749231, -0.13799816],\n",
       "          [-0.14550471,  0.03182001, -0.12691548, ...,  0.04782498,\n",
       "           -0.1356529 , -0.04355934],\n",
       "          [-0.08534821, -0.20270443,  0.01745207, ..., -0.33479705,\n",
       "           -0.28703666,  0.57965493]], dtype=float32),\n",
       "   (((), ((), ())),\n",
       "    ((array([[-0.00700635, -0.81279695, -0.1969731 , ...,  0.33134758,\n",
       "              -0.01820136,  0.09090405],\n",
       "             [-0.09393045, -0.14250134,  0.03360443, ..., -0.26035592,\n",
       "               0.0903319 ,  0.07371619],\n",
       "             [-0.0230589 , -0.1425545 ,  0.05566799, ..., -0.10225294,\n",
       "              -0.10230286,  0.12587823],\n",
       "             ...,\n",
       "             [-0.06393539,  0.22706407, -0.24334547, ..., -0.20449103,\n",
       "              -0.04915347,  0.1844755 ],\n",
       "             [-0.0095596 , -0.35859162,  0.09128597, ...,  0.07574733,\n",
       "              -0.17606777, -0.01880231],\n",
       "             [ 0.08475196,  0.05819269,  0.08133972, ..., -0.21196827,\n",
       "              -0.01953081,  0.01366328]], dtype=float32),\n",
       "      array([ 0.4810392 ,  0.73634326,  0.9889985 ,  0.67161983,  0.29044554,\n",
       "              0.23193635,  0.99064386,  0.50620097,  0.9710872 ,  0.19312796,\n",
       "              0.46180254,  0.2760385 ,  0.91799635, -0.2144793 ,  0.49922776,\n",
       "              0.31314176,  0.53773975,  0.53897965,  0.70933384,  0.58248895,\n",
       "              0.0452533 ,  0.6249373 ,  0.04000624, -0.10898256,  0.3886352 ,\n",
       "              0.2590279 , -0.01021934,  0.2643062 ,  0.72320473,  0.0766114 ,\n",
       "              0.59131575,  0.5433216 ,  0.5811504 ,  0.95103   ,  0.26416335,\n",
       "              0.25657627,  0.10822742,  0.24427594,  0.4209123 ,  0.461082  ,\n",
       "              0.3055314 ,  0.49885878,  0.78912055,  0.11642344,  0.36703688,\n",
       "              0.4974254 ,  0.31740388,  0.38847756,  0.3398291 ,  0.23042531,\n",
       "              0.58498555,  0.5168723 ,  0.4584711 , -0.32169876,  0.48722234,\n",
       "              0.49131462,  0.44849512,  0.36401603,  0.7137197 ,  0.40609804,\n",
       "              0.5991057 , -0.1126846 ,  1.294527  ,  0.74407685,  0.8928553 ,\n",
       "              0.37594512,  0.6087865 ,  0.7750591 ,  0.37242538,  0.21788228,\n",
       "              1.0535476 ,  0.3156904 ,  0.09935088,  0.3382641 ,  0.73736113,\n",
       "              0.36467126, -1.0371883 ,  0.28534466,  0.5906608 ,  0.70373124,\n",
       "              0.8901208 ,  0.18917249, -0.01196874,  0.4932649 ,  0.32766035,\n",
       "              0.6533499 ,  0.48376676,  0.06134075,  0.53104776,  0.29785898,\n",
       "              1.0028832 ,  0.58471537,  0.6402257 ,  0.49529165,  0.3739395 ,\n",
       "              0.3320033 ,  0.03996351,  0.44755435,  0.06317542,  0.6450296 ,\n",
       "              0.6910326 ,  0.5372048 ,  0.94523764,  0.5750833 ,  0.82749754,\n",
       "              0.70884985,  0.5707244 ,  0.29116   ,  0.78084904,  0.4761313 ,\n",
       "              0.453841  ,  0.91280144,  0.54431   ,  0.35632083,  0.12664548,\n",
       "              0.24416403,  0.31940365,  0.08524509,  0.24684432,  0.17217816,\n",
       "              0.84888947,  0.5665264 ,  0.3517982 ,  0.5354968 ,  0.7965402 ,\n",
       "              0.59286445,  0.18212956,  0.50214547,  0.64510965,  0.70618224,\n",
       "              1.3201958 ,  1.0683507 ,  0.8350688 ,  0.8750094 ,  1.0750743 ,\n",
       "              0.73605204,  0.72488177,  0.92718184,  1.0871676 ,  0.42776826,\n",
       "              1.1019021 ,  0.40965843,  1.0297759 ,  0.8563879 ,  1.1545217 ,\n",
       "              0.9695928 ,  1.0836124 ,  0.97251964,  0.68340605,  1.0699238 ,\n",
       "              0.7606038 ,  1.2672399 ,  0.83551794,  0.510382  ,  0.9926698 ,\n",
       "              0.88841003,  0.6233576 ,  0.6959777 ,  0.79380065,  0.89899325,\n",
       "              1.1293013 ,  1.1605233 ,  1.0784434 ,  1.1262088 ,  0.7352574 ,\n",
       "              0.48209524,  0.74128157,  0.9368951 ,  0.8043482 ,  0.99227744,\n",
       "              0.92664653,  1.006906  ,  0.4543911 ,  0.3816918 ,  1.0578282 ,\n",
       "              0.9938755 ,  0.7220542 ,  1.1236831 ,  0.8665643 ,  1.1936883 ,\n",
       "              1.0230021 ,  0.5316785 ,  0.6425138 ,  0.91377723,  0.9773801 ,\n",
       "              0.7179896 ,  1.0913244 ,  0.77133423,  0.8234479 ,  0.7928564 ,\n",
       "              0.827244  ,  0.84293973,  0.7651822 ,  1.051438  ,  0.8797342 ,\n",
       "              0.6119008 ,  0.6206689 ,  1.0420687 ,  0.6086478 ,  0.68341786,\n",
       "              0.9584359 ,  1.2544436 ,  0.97103274,  0.97135586,  0.9238858 ,\n",
       "              0.8624975 ,  1.1502405 ,  1.0495043 ,  0.8172998 ,  0.76325154,\n",
       "              0.16255285,  0.66237503,  0.92097354,  0.83778983,  1.1161754 ,\n",
       "              1.0328218 ,  0.6527062 ,  1.1081703 ,  1.1934226 ,  1.1747388 ,\n",
       "              0.8301712 ,  1.1224796 ,  1.2767396 ,  0.6653896 ,  0.47177872,\n",
       "              0.8454497 ,  0.9304573 ,  1.0087795 ,  0.6204676 ,  0.8211065 ,\n",
       "              1.0593516 ,  0.7787525 ,  0.63764775,  1.0188485 ,  0.9609811 ,\n",
       "              0.36893222,  0.60578734,  0.7883475 ,  0.6545211 ,  1.1971194 ,\n",
       "              0.8144442 ,  0.8440437 ,  0.36850986,  0.43635494,  0.71801716,\n",
       "              0.50993997,  0.71929103,  0.50296915,  0.9338318 ,  0.5702631 ,\n",
       "              0.62604505,  0.8914634 ,  0.5509539 ,  0.8953204 ,  0.8796218 ,\n",
       "              1.049201  ,  0.09496798,  1.3555394 ,  0.8599645 ,  1.4351146 ,\n",
       "              0.5501235 ,  0.7541557 ,  0.83632314,  0.34097394,  1.1659474 ,\n",
       "              0.8254578 ,  0.43452662,  0.6524608 ,  0.80777556,  1.1704161 ,\n",
       "              0.84995335,  1.3162812 ,  0.5622513 ,  0.6352417 ,  0.93842167,\n",
       "              0.4818763 ,  1.4284763 ,  0.9719235 ,  0.62541693,  0.4959336 ,\n",
       "              0.7412683 ,  0.7862043 ,  1.3720953 ,  0.6508241 ,  1.3664818 ,\n",
       "              0.5451522 ,  0.5699404 ,  0.8839319 ,  0.7259547 ,  1.0398918 ,\n",
       "              0.6157066 ,  0.6549328 ,  0.6293646 ,  1.2659034 ,  0.69781154,\n",
       "              0.8201043 ,  1.1870489 ,  0.910566  ,  0.98524356,  0.54076475,\n",
       "              1.3277112 ,  1.1512077 ,  0.8937793 ,  0.5602883 ,  0.56190175,\n",
       "              0.8038671 ,  0.48130774,  0.7223985 ,  1.324966  ,  1.5643414 ,\n",
       "              0.95849866,  0.69425744,  0.7274782 ,  0.42115253,  1.0646503 ,\n",
       "              1.2895944 ,  1.3123035 ,  0.65643483,  0.97750086,  1.0890598 ,\n",
       "              1.5195119 ,  1.139688  ,  1.231676  ,  0.70574844,  1.3439915 ,\n",
       "              0.49039766,  0.86967134,  0.78117895,  1.0973657 ,  0.79160464,\n",
       "              0.39725387,  0.59658563,  1.5775762 ,  0.6575871 ,  0.9264174 ,\n",
       "              0.5801511 ,  0.58822507,  1.0993942 ,  1.4876004 ,  1.0329367 ,\n",
       "              0.8708161 ,  0.5112492 ,  1.3540978 ,  1.3436035 ,  0.7472466 ,\n",
       "              0.8533474 ,  0.9848784 ,  1.0941235 ,  0.89377123,  1.0922784 ,\n",
       "              0.49577436,  0.58479685,  1.5948839 ,  0.7264593 ,  0.777279  ,\n",
       "              1.3581132 ,  1.3459364 ,  1.3075787 ,  0.85867643,  1.3203573 ,\n",
       "              1.1513699 ,  1.1055804 ,  0.9626765 ,  1.2449455 ,  0.3774419 ,\n",
       "              1.4468083 ,  0.66255826,  1.2331271 ,  0.84613496,  1.0114211 ,\n",
       "              0.84737206,  1.6215127 ,  0.73023665,  0.9714852 ,  0.6293015 ,\n",
       "              1.1343466 ,  1.1855383 ,  1.4401944 ,  0.90512943,  0.9705356 ,\n",
       "              1.3087895 ,  1.2347229 ,  0.8159456 ,  0.5893001 ,  0.48512372,\n",
       "              1.027058  ,  0.34787303,  1.0726554 ,  0.45980442,  0.54572797,\n",
       "             -0.102742  ,  0.48556134,  0.8904753 ,  0.18256438,  0.45832574,\n",
       "              0.17035913,  0.15001598,  0.34487695,  0.30196148,  1.1843275 ,\n",
       "              0.3796659 ,  0.24606799,  0.9578799 ,  0.7355004 ,  1.1289264 ,\n",
       "              0.9063994 ,  0.1606932 ,  0.18212695,  1.0754205 ,  0.32836616,\n",
       "              0.75367874,  0.3291658 ,  1.1916919 ,  0.06836634,  0.20186338,\n",
       "              0.51647174,  0.20015255,  0.7015189 ,  0.30263606,  0.17508501,\n",
       "              0.4901561 ,  0.99966   ,  0.74852455,  0.12618658,  1.1697444 ,\n",
       "              0.42376062,  0.29154754,  0.2713197 ,  1.0151441 ,  1.2235026 ,\n",
       "              0.1015129 ,  0.14405863,  0.4532768 ,  0.54337823, -0.03027476,\n",
       "              0.37026402,  1.0060347 ,  1.1701945 ,  0.25140995,  0.39666352,\n",
       "              0.18848121,  0.33075717,  0.7425488 ,  1.0573978 ,  0.08103536,\n",
       "              0.19597384,  0.9212952 ,  0.3774042 ,  0.0976241 ,  0.6271684 ,\n",
       "              1.0854757 ,  0.3601231 ,  0.6065636 ,  0.73911166,  0.14494157,\n",
       "              0.16624656,  0.556183  ,  0.50444865,  0.5516209 ,  0.19835006,\n",
       "              1.2365141 ,  0.40905863,  0.25251633,  0.36206582,  0.880252  ,\n",
       "              0.38453928,  0.7895253 ,  0.5159386 ,  0.3494469 ,  0.11838622,\n",
       "              1.3138663 ,  1.2769718 ,  0.5128609 ,  0.21741287,  0.06412268,\n",
       "             -0.18080075,  0.3243802 ,  0.4544132 ,  0.065402  ,  0.8556332 ,\n",
       "              1.0298569 ,  0.32207048,  0.6954042 ,  1.2474737 ,  0.73981273,\n",
       "              1.144362  ,  0.23302504,  1.4777322 ,  0.13573705,  0.9580146 ,\n",
       "              0.32386002,  0.95656043,  0.1644391 ,  1.1655443 ,  0.24279605,\n",
       "              0.63736445,  0.45899773,  0.15210181,  0.20272261,  0.853788  ,\n",
       "              0.16945307,  0.40352044,  0.26729828,  0.9195644 ,  0.63865256,\n",
       "              1.209869  ,  0.4321867 ,  0.34085003,  1.1458995 ,  1.0463768 ,\n",
       "              0.18228231,  0.7397248 ], dtype=float32)),),\n",
       "    ()),\n",
       "   (),\n",
       "   ()),\n",
       "  {'__marker_for_cached_weights_': ()}),\n",
       " (((), (((), ((), ())), ((), ()), ()), (), ()),\n",
       "  {'__marker_for_cached_state_': ()}))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Siamese()\n",
    "model.init_from_file('models/model.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "6c856h_ImItX"
   },
   "outputs": [],
   "source": [
    "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
    "    \"\"\"Function to test the accuracy of the model.\n",
    "\n",
    "    Args:\n",
    "        test_Q1 (numpy.ndarray): Array of Q1 questions.\n",
    "        test_Q2 (numpy.ndarray): Array of Q2 questions.\n",
    "        y (numpy.ndarray): Array of actual target.\n",
    "        threshold (float): Desired threshold.\n",
    "        model: The Siamese model.\n",
    "        vocab (collections.defaultdict): The vocabulary used.\n",
    "        data_generator (function): Data generator function. Defaults to data_generator.\n",
    "        batch_size (int, optional): Size of the batches. Defaults to 64.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model.\n",
    "    \"\"\"    \n",
    "    \n",
    "    \n",
    "    accuracy1, TP1, TN1, FN1, FP1 = 0,0,0,0,0\n",
    "    ### START CODE HERE (Replace 'None' with your code) ###\n",
    "    for i in range(0, len(test_Q1), batch_size):\n",
    "        # Call the data generator (built in Ex 01) with shuffle= None\n",
    "        # use batch size chuncks of questions as Q1 & Q2 arguments of the data generator. e.g x[i:i + batch_size]\n",
    "        # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n",
    "        q1, q2 = next(data_generator(test_Q1[i: i + batch_size], \n",
    "                                     test_Q2[i: i+batch_size], batch_size, \n",
    "                                     pad=vocab['<PAD>'], shuffle=False))\n",
    "\n",
    "        # use batch size chuncks of actual output targets (same syntax as example above)\n",
    "        if i+batch_size < len(y):\n",
    "            y_test = y[i: i + batch_size]\n",
    "#         else: \n",
    "#             y_test = y[i:]\n",
    "        # Call the model    \n",
    "            v1, v2 = model((q1,q2))\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                # take dot product to compute cos similarity of each pair of entries, v1[j], v2[j]\n",
    "                # don't forget to transpose the second argument\n",
    "                d = fastnp.dot(v1[j],v2[j].T)\n",
    "                # is d greater than the threshold?\n",
    "                res = int(d > threshold)\n",
    "                correct = res == y_test[j]\n",
    "                if res:\n",
    "                    if correct:\n",
    "                        TP1+=1\n",
    "                    else:\n",
    "                        FP1+=1\n",
    "                else:\n",
    "                    if correct:\n",
    "                        TN1+=1\n",
    "                    else:\n",
    "                        FN1+=1\n",
    "                # increment accurancy if y_test is equal `res`\n",
    "                accuracy1 += int(correct)\n",
    "              \n",
    "    # compute accuracy using accuracy and total length of test questions\n",
    "    accuracy1 = accuracy1 / len(test_Q1)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return accuracy1, TP1, TN1, FN1, FP1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "UYdgz-yymSgP"
   },
   "outputs": [],
   "source": [
    "accuracy,  TP, TN, FN, FP  = classify(q1_test,q2_test, y_test, 0.7, model, vocab, batch_size = 256) \n",
    "# print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.7373654, dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7373654424568624"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31738, 42789, 5489, 20848)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP, TN, FN, FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7388860247461929"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP+TN)/(TP+TN+FN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the model is 0.737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator):\n",
    "  \n",
    "    q1 = nltk.word_tokenize(question1) \n",
    "    q2 = nltk.word_tokenize(question2)  \n",
    "    Q1, Q2 = [], []\n",
    "    for word in q1: \n",
    "        Q1 += [vocab[word]]\n",
    "    for word in q2: \n",
    "        Q2 += [vocab[word]]\n",
    "\n",
    "    Q1, Q2 = next(data_generator([Q1], [Q2], 1, vocab['<PAD>']))\n",
    "    v1, v2 = model((Q1,Q2))\n",
    "\n",
    "    d = fastnp.dot(v1, v2.T)\n",
    "    res = d > threshold\n",
    "    \n",
    "    \n",
    "    print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n",
    "    print(\"Similarity   = \", d)\n",
    "    print(\"res = \", res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"When will I see you?\"\n",
    "question2 = \"When can I see you again?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1  =  [[598  97  25 180  91  11   1   1]] \n",
      "Q2  =  [[ 598   24   25  180   91 2029   11    1]]\n",
      "Similarity   =  [[0.9333575]]\n",
      "res =  [[ True]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ True]], dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(question1 , question2, 0.8, model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgaEAw2QYfLv"
   },
   "source": [
    "**Part 5: Sentence-BERT** (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn8vnw9RaJWG"
   },
   "source": [
    "**Task:** Get acquinted with Sentence-BERT model and work with that model to get results on quora dataset.  \n",
    "\n",
    "https://arxiv.org/abs/1908.10084\n",
    " \n",
    "https://huggingface.co/sentence-transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SentenceTransformer and cosine similarty\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# distilbert model is used\n",
    "model_bert = SentenceTransformer('sentence-transformers/quora-distilbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding question1 list using distilbert model\n",
    "encoded_q1 = model_bert.encode(test['question1'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding question2 list using distilbert model\n",
    "\n",
    "encoded_q2 = model_bert.encode(test['question2'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to caluclate accuracy of bert model\n",
    "def accurecy_bert(q1, q2, y, threshold):\n",
    "    accuracy_bert = 0\n",
    "    for i in range(0, len(test)):\n",
    "\n",
    "        d = 1-cosine(q1[i],q2[i])\n",
    "        res = d > threshold\n",
    "        accuracy_bert += (y[i] == res)\n",
    "    accuracy_bert = accuracy_bert / len(y)\n",
    "    return accuracy_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7969566249802121"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurecy_bert(encoded_q1, encoded_q2, y_test, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to caluclate accuracy of bert model\n",
    "def classification_bert(q1, q2, y, threshold):\n",
    "    TP, TN, FP, FN = 0,0,0,0\n",
    "    accuracy_bert = 0\n",
    "    for i in range(0, len(test)):\n",
    "\n",
    "        d = 1-cosine(q1[i],q2[i])\n",
    "        res = d > threshold\n",
    "        accuracy_bert += (y[i] == res)\n",
    "        if y[i]==res==1:\n",
    "            TP+=1\n",
    "        elif y[i]==res==0:\n",
    "            TN+=1\n",
    "        elif y[i]==1 and res ==0:\n",
    "            FN+=1\n",
    "        elif y[i]==0 and res ==1:\n",
    "            FP+=1\n",
    "            \n",
    "    accuracy_bert = accuracy_bert / len(y)\n",
    "    return accuracy_bert, TP,TN,FN,FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, TP, TN, FN, FP = classification_bert(encoded_q1, encoded_q2, y_test, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7969566249802121"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36826, 43724, 490, 20032)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP, TN, FN, FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7969566249802121"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP+TN)/(TP+TN+FN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy using distilbert model is 0.797.\n",
    "Accuracy of the model can be increased by fine tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EL5fv1xKaWt1"
   },
   "source": [
    "**Task** Compare the results of LSTM-based model and Sentence BERT. Look at the particular examples and make conclusions. Write down your thoughts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "uQcfLol4a0rR"
   },
   "outputs": [],
   "source": [
    "# your code & results description here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the similarity between question using lstm Siamese model\n",
    "def predict_lstm(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\n",
    "    q1 = nltk.word_tokenize(question1)  \n",
    "    q2 = nltk.word_tokenize(question2)  \n",
    "    Q1, Q2 = [], []\n",
    "    for word in q1:   \n",
    "        Q1 += [vocab[word]]\n",
    "    for word in q2:  \n",
    "        Q2 += [vocab[word]]\n",
    "        \n",
    "    Q1, Q2 = next(data_generator([Q1], [Q2], 1, vocab['<PAD>']))\n",
    "    v1, v2 = model([Q1,Q2])\n",
    "\n",
    "    d = fastnp.dot(v1, v2.T)\n",
    "    res = d > threshold\n",
    "    \n",
    "    print('question1:' ,question1)\n",
    "    print('question2:' ,question2)    \n",
    "    print(\"Similarity:\", d)\n",
    "    print('Is similar:', res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample test question which are not similar\n",
    "question1 = 'I am visiting Sri Lanka soonfor 9 days, how can I pick up Sri Lankan girls and have fun?'\n",
    "\n",
    "question2 = 'Do Indians hate Sri Lankans?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1: I am visiting Sri Lanka soonfor 9 days, how can I pick up Sri Lankan girls and have fun?\n",
      "question2: Do Indians hate Sri Lankans?\n",
      "Similarity: [[0.15066601]]\n",
      "Is similar: [[False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[False]], dtype=bool)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(question1 , question2, 0.7, model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "xkpPxc_Xa6Ll"
   },
   "outputs": [],
   "source": [
    "# predicting the similarity between question using distilbert model\n",
    "\n",
    "def predict_bert(question1, question2, threshold, model):\n",
    "    q1, q2 = model.encode([question1, question2])\n",
    "    d = 1-cosine(q1, q2)\n",
    "    res = d > threshold\n",
    "    \n",
    "    print('question1:' ,question1)\n",
    "    print('question2:' ,question2)    \n",
    "    print(\"Similarity:\", d)\n",
    "    print('Is similar:', res)\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1: I am visiting Sri Lanka soonfor 9 days, how can I pick up Sri Lankan girls and have fun?\n",
      "question2: Do Indians hate Sri Lankans?\n",
      "Similarity: 0.3482406437397003\n",
      "Is similar: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_bert(question1, question2, 0.7, model_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weak and ignorance is not an impediment to survival, arrogance is? (in Japanese)'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.question2[2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample test question which are similar\n",
    "\n",
    "question3 = 'The weak and ignorance is not an impediment to survival, arrogance is?'\n",
    "question4= 'The weak and ignorance is not an impediment to survival, arrogance is? (in Japanese)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1: The weak and ignorance is not an impediment to survival, arrogance is?\n",
      "question2: The weak and ignorance is not an impediment to survival, arrogance is? (in Japanese)\n",
      "Similarity: [[0.79751545]]\n",
      "Is similar: [[ True]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ True]], dtype=bool)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(question3 , question4, 0.7, model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1: The weak and ignorance is not an impediment to survival, arrogance is?\n",
      "question2: The weak and ignorance is not an impediment to survival, arrogance is? (in Japanese)\n",
      "Similarity: 0.985177218914032\n",
      "Is similar: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_bert(question3, question4, 0.7, model_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the predictions and accuracy both models are working with nearly similar accuracy, distilbert have abitof upper hand. But according to the classification report. Both Siamese Lstm and Distilbert model have alot of flase positive cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
